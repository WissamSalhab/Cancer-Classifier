{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\n%matplotlib inline \nimport matplotlib.pyplot as plt"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "1- Dataset"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-02-24 11:48:00--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cell_samples.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20675 (20K) [text/csv]\nSaving to: \u2018cell_samples.csv\u2019\n\ncell_samples.csv    100%[===================>]  20.19K  --.-KB/s    in 0.02s   \n\n2020-02-24 11:48:00 (959 KB/s) - \u2018cell_samples.csv\u2019 saved [20675/20675]\n\n"
                }
            ],
            "source": "## 1- Load the dataset\n!wget -O cell_samples.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cell_samples.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Clump</th>\n      <th>UnifSize</th>\n      <th>UnifShape</th>\n      <th>MargAdh</th>\n      <th>SingEpiSize</th>\n      <th>BareNuc</th>\n      <th>BlandChrom</th>\n      <th>NormNucl</th>\n      <th>Mit</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000025</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002945</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1015425</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1016277</td>\n      <td>6</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1017023</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1017122</td>\n      <td>8</td>\n      <td>10</td>\n      <td>10</td>\n      <td>8</td>\n      <td>7</td>\n      <td>10</td>\n      <td>9</td>\n      <td>7</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1018099</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "        ID  Clump  UnifSize  UnifShape  MargAdh  SingEpiSize BareNuc  \\\n0  1000025      5         1          1        1            2       1   \n1  1002945      5         4          4        5            7      10   \n2  1015425      3         1          1        1            2       2   \n3  1016277      6         8          8        1            3       4   \n4  1017023      4         1          1        3            2       1   \n5  1017122      8        10         10        8            7      10   \n6  1018099      1         1          1        1            2      10   \n\n   BlandChrom  NormNucl  Mit  Class  \n0           3         1    1      2  \n1           3         2    1      2  \n2           3         1    1      2  \n3           3         7    1      2  \n4           3         1    1      2  \n5           9         7    1      4  \n6           3         1    1      2  "
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "cell_df = pd.read_csv(\"cell_samples.csv\")\ncell_df.head(7)"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "ID             int64\nClump          int64\nUnifSize       int64\nUnifShape      int64\nMargAdh        int64\nSingEpiSize    int64\nBareNuc        int64\nBlandChrom     int64\nNormNucl       int64\nMit            int64\nClass          int64\ndtype: object"
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\ncell_df.dtypes"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]])"
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize',\n       'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']] .values  #.astype(float)\nX[0:5]\n"
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n       1])"
                    },
                    "execution_count": 54,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y = cell_df['Class'].values\n#y[0:5]\ny[y<4]=0\ny[y>2]=1\ny\n"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "array([[ 0.19790469, -0.70221201, -0.74177362, -0.63936553, -0.5556085 ,\n        -0.69885309, -0.18182716, -0.61292736, -0.34839971],\n       [ 0.19790469,  0.27725185,  0.26278299,  0.75803177,  1.69516613,\n         1.77286724, -0.18182716, -0.28510482, -0.34839971],\n       [-0.51164337, -0.70221201, -0.74177362, -0.63936553, -0.5556085 ,\n        -0.4242175 , -0.18182716, -0.61292736, -0.34839971],\n       [ 0.55267873,  1.58320366,  1.6021918 , -0.63936553, -0.10545357,\n         0.12505369, -0.18182716,  1.3540079 , -0.34839971],\n       [-0.15686934, -0.70221201, -0.74177362,  0.05933312, -0.5556085 ,\n        -0.69885309, -0.18182716, -0.61292736, -0.34839971]])"
                    },
                    "execution_count": 55,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\nX[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "2- Model"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Train/Test dataset\n\nOkay, we split our dataset into train and test set:\n"
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set: (546, 9) (546,)\nTest set: (137, 9) (137,)\n"
                }
            ],
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Lets build our model using LogisticRegression from Scikit-learn package. This function implements logistic regression and can use different numerical optimizers to find parameters, including \u2018newton-cg\u2019, \u2018lbfgs\u2019, \u2018liblinear\u2019, \u2018sag\u2019, \u2018saga\u2019 solvers. You can find extensive information about the pros and cons of these optimizers if you search it in internet.\n\nThe version of Logistic Regression in Scikit-learn, support regularization. Regularization is a technique used to solve the overfitting problem in machine learning models. C parameter indicates inverse of regularization strength which must be a positive float. Smaller values specify stronger regularization. Now lets fit our model with train set:\n"
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False)"
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLR"
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       0, 0, 0, 0, 1])"
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yhat = LR.predict(X_test)\nyhat"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "predict_proba returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 1, P(Y=1|X), and second column is probability of class 0, P(Y=0|X):"
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.87580328, 0.12419672],\n       [0.03028476, 0.96971524],\n       [0.85861432, 0.14138568],\n       [0.0462123 , 0.9537877 ],\n       [0.89738151, 0.10261849],\n       [0.86084728, 0.13915272],\n       [0.88757566, 0.11242434],\n       [0.87224218, 0.12775782],\n       [0.00494664, 0.99505336],\n       [0.87291713, 0.12708287],\n       [0.84201013, 0.15798987],\n       [0.03398521, 0.96601479],\n       [0.13748273, 0.86251727],\n       [0.03431598, 0.96568402],\n       [0.03169355, 0.96830645],\n       [0.89739415, 0.10260585],\n       [0.8644111 , 0.1355889 ],\n       [0.78071928, 0.21928072],\n       [0.82473522, 0.17526478],\n       [0.81671427, 0.18328573],\n       [0.02511887, 0.97488113],\n       [0.90823713, 0.09176287],\n       [0.157517  , 0.842483  ],\n       [0.33819244, 0.66180756],\n       [0.41987407, 0.58012593],\n       [0.12283464, 0.87716536],\n       [0.8747583 , 0.1252417 ],\n       [0.85779505, 0.14220495],\n       [0.02838821, 0.97161179],\n       [0.06266967, 0.93733033],\n       [0.04836208, 0.95163792],\n       [0.72430639, 0.27569361],\n       [0.17205513, 0.82794487],\n       [0.87373514, 0.12626486],\n       [0.84305243, 0.15694757],\n       [0.88596522, 0.11403478],\n       [0.01400716, 0.98599284],\n       [0.91906679, 0.08093321],\n       [0.90936448, 0.09063552],\n       [0.91855434, 0.08144566],\n       [0.82561098, 0.17438902],\n       [0.74703414, 0.25296586],\n       [0.88541762, 0.11458238],\n       [0.11450507, 0.88549493],\n       [0.03772685, 0.96227315],\n       [0.91906679, 0.08093321],\n       [0.89799983, 0.10200017],\n       [0.89862735, 0.10137265],\n       [0.90880806, 0.09119194],\n       [0.16771114, 0.83228886],\n       [0.84290368, 0.15709632],\n       [0.83142255, 0.16857745],\n       [0.87277023, 0.12722977],\n       [0.76105448, 0.23894552],\n       [0.77491639, 0.22508361],\n       [0.91906679, 0.08093321],\n       [0.03787939, 0.96212061],\n       [0.87224218, 0.12775782],\n       [0.85861432, 0.14138568],\n       [0.85779505, 0.14220495],\n       [0.88676283, 0.11323717],\n       [0.12962274, 0.87037726],\n       [0.09440976, 0.90559024],\n       [0.85853395, 0.14146605],\n       [0.39944953, 0.60055047],\n       [0.15734484, 0.84265516],\n       [0.02447071, 0.97552929],\n       [0.85861432, 0.14138568],\n       [0.86016996, 0.13983004],\n       [0.88609888, 0.11390112],\n       [0.18982003, 0.81017997],\n       [0.00953735, 0.99046265],\n       [0.85934966, 0.14065034],\n       [0.87545842, 0.12454158],\n       [0.89941215, 0.10058785],\n       [0.04138692, 0.95861308],\n       [0.88886112, 0.11113888],\n       [0.86055021, 0.13944979],\n       [0.21931118, 0.78068882],\n       [0.11132113, 0.88867887],\n       [0.8878681 , 0.1121319 ],\n       [0.88541762, 0.11458238],\n       [0.92060002, 0.07939998],\n       [0.84522665, 0.15477335],\n       [0.08205769, 0.91794231],\n       [0.04908022, 0.95091978],\n       [0.72039386, 0.27960614],\n       [0.00765013, 0.99234987],\n       [0.91906679, 0.08093321],\n       [0.87135664, 0.12864336],\n       [0.50654155, 0.49345845],\n       [0.20753772, 0.79246228],\n       [0.91906679, 0.08093321],\n       [0.91906679, 0.08093321],\n       [0.90880806, 0.09119194],\n       [0.00571685, 0.99428315],\n       [0.90936448, 0.09063552],\n       [0.88853663, 0.11146337],\n       [0.87911881, 0.12088119],\n       [0.05600097, 0.94399903],\n       [0.88609888, 0.11390112],\n       [0.18624541, 0.81375459],\n       [0.90823713, 0.09176287],\n       [0.82617147, 0.17382853],\n       [0.07320492, 0.92679508],\n       [0.84342313, 0.15657687],\n       [0.04330974, 0.95669026],\n       [0.87373514, 0.12626486],\n       [0.89862735, 0.10137265],\n       [0.03360268, 0.96639732],\n       [0.91906679, 0.08093321],\n       [0.8980124 , 0.1019876 ],\n       [0.17125339, 0.82874661],\n       [0.89092862, 0.10907138],\n       [0.84272833, 0.15727167],\n       [0.89739415, 0.10260585],\n       [0.88752398, 0.11247602],\n       [0.84610534, 0.15389466],\n       [0.09835175, 0.90164825],\n       [0.1948083 , 0.8051917 ],\n       [0.02422265, 0.97577735],\n       [0.19455245, 0.80544755],\n       [0.0908504 , 0.9091496 ],\n       [0.87311508, 0.12688492],\n       [0.88609888, 0.11390112],\n       [0.03585746, 0.96414254],\n       [0.78590788, 0.21409212],\n       [0.89862735, 0.10137265],\n       [0.1035629 , 0.8964371 ],\n       [0.88596522, 0.11403478],\n       [0.02266048, 0.97733952],\n       [0.88609888, 0.11390112],\n       [0.81334105, 0.18665895],\n       [0.90880806, 0.09119194],\n       [0.90880806, 0.09119194],\n       [0.8288837 , 0.1711163 ],\n       [0.01935487, 0.98064513]])"
                    },
                    "execution_count": 59,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yhat_prob = LR.predict_proba(X_test)\nyhat_prob"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "3- Evaluation"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "jaccard index\n\nLets try jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of two label sets. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.9708029197080292"
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "log loss\n\nNow, lets try log loss for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1. Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.16403570775581278"
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import log_loss\nlog_loss(y_test, yhat_prob)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "conda-env-python-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}