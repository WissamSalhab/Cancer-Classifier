{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Decision Tree"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np \nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "1- Dataset"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Load the dataset:"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-02-23 16:56:18--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cell_samples.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20675 (20K) [text/csv]\nSaving to: \u2018cell_samples.csv\u2019\n\ncell_samples.csv    100%[===================>]  20.19K  --.-KB/s    in 0.03s   \n\n2020-02-23 16:56:18 (664 KB/s) - \u2018cell_samples.csv\u2019 saved [20675/20675]\n\n"
                }
            ],
            "source": "## 1- Load the dataset\n!wget -O cell_samples.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cell_samples.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Clump</th>\n      <th>UnifSize</th>\n      <th>UnifShape</th>\n      <th>MargAdh</th>\n      <th>SingEpiSize</th>\n      <th>BareNuc</th>\n      <th>BlandChrom</th>\n      <th>NormNucl</th>\n      <th>Mit</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000025</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002945</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1015425</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1016277</td>\n      <td>6</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1017023</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1017122</td>\n      <td>8</td>\n      <td>10</td>\n      <td>10</td>\n      <td>8</td>\n      <td>7</td>\n      <td>10</td>\n      <td>9</td>\n      <td>7</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1018099</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1018561</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1033078</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1033078</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1035283</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1036172</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1041801</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1043999</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1044572</td>\n      <td>8</td>\n      <td>7</td>\n      <td>5</td>\n      <td>10</td>\n      <td>7</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1047630</td>\n      <td>7</td>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1048672</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1049815</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1050670</td>\n      <td>10</td>\n      <td>7</td>\n      <td>7</td>\n      <td>6</td>\n      <td>4</td>\n      <td>10</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1050718</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1054590</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>10</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1054593</td>\n      <td>10</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>7</td>\n      <td>10</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1056784</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1057013</td>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>?</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1059552</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1065726</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1066373</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1066979</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1067444</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1070935</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1070935</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>1071760</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>1072179</td>\n      <td>10</td>\n      <td>7</td>\n      <td>7</td>\n      <td>3</td>\n      <td>8</td>\n      <td>5</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1074610</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1075123</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1079304</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>1080185</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>8</td>\n      <td>6</td>\n      <td>1</td>\n      <td>8</td>\n      <td>9</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1081791</td>\n      <td>6</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1084584</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>9</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1091262</td>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1096800</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>9</td>\n      <td>6</td>\n      <td>?</td>\n      <td>7</td>\n      <td>8</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1099510</td>\n      <td>10</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1100524</td>\n      <td>6</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1102573</td>\n      <td>5</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>10</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>1103608</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n      <td>10</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1103722</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1105257</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>4</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1105524</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1106095</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>1106829</td>\n      <td>7</td>\n      <td>8</td>\n      <td>7</td>\n      <td>2</td>\n      <td>4</td>\n      <td>8</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "         ID  Clump  UnifSize  UnifShape  MargAdh  SingEpiSize BareNuc  \\\n0   1000025      5         1          1        1            2       1   \n1   1002945      5         4          4        5            7      10   \n2   1015425      3         1          1        1            2       2   \n3   1016277      6         8          8        1            3       4   \n4   1017023      4         1          1        3            2       1   \n5   1017122      8        10         10        8            7      10   \n6   1018099      1         1          1        1            2      10   \n7   1018561      2         1          2        1            2       1   \n8   1033078      2         1          1        1            2       1   \n9   1033078      4         2          1        1            2       1   \n10  1035283      1         1          1        1            1       1   \n11  1036172      2         1          1        1            2       1   \n12  1041801      5         3          3        3            2       3   \n13  1043999      1         1          1        1            2       3   \n14  1044572      8         7          5       10            7       9   \n15  1047630      7         4          6        4            6       1   \n16  1048672      4         1          1        1            2       1   \n17  1049815      4         1          1        1            2       1   \n18  1050670     10         7          7        6            4      10   \n19  1050718      6         1          1        1            2       1   \n20  1054590      7         3          2       10            5      10   \n21  1054593     10         5          5        3            6       7   \n22  1056784      3         1          1        1            2       1   \n23  1057013      8         4          5        1            2       ?   \n24  1059552      1         1          1        1            2       1   \n25  1065726      5         2          3        4            2       7   \n26  1066373      3         2          1        1            1       1   \n27  1066979      5         1          1        1            2       1   \n28  1067444      2         1          1        1            2       1   \n29  1070935      1         1          3        1            2       1   \n30  1070935      3         1          1        1            1       1   \n31  1071760      2         1          1        1            2       1   \n32  1072179     10         7          7        3            8       5   \n33  1074610      2         1          1        2            2       1   \n34  1075123      3         1          2        1            2       1   \n35  1079304      2         1          1        1            2       1   \n36  1080185     10        10         10        8            6       1   \n37  1081791      6         2          1        1            1       1   \n38  1084584      5         4          4        9            2      10   \n39  1091262      2         5          3        3            6       7   \n40  1096800      6         6          6        9            6       ?   \n41  1099510     10         4          3        1            3       3   \n42  1100524      6        10         10        2            8      10   \n43  1102573      5         6          5        6           10       1   \n44  1103608     10        10         10        4            8       1   \n45  1103722      1         1          1        1            2       1   \n46  1105257      3         7          7        4            4       9   \n47  1105524      1         1          1        1            2       1   \n48  1106095      4         1          1        3            2       1   \n49  1106829      7         8          7        2            4       8   \n\n    BlandChrom  NormNucl  Mit  Class  \n0            3         1    1      2  \n1            3         2    1      2  \n2            3         1    1      2  \n3            3         7    1      2  \n4            3         1    1      2  \n5            9         7    1      4  \n6            3         1    1      2  \n7            3         1    1      2  \n8            1         1    5      2  \n9            2         1    1      2  \n10           3         1    1      2  \n11           2         1    1      2  \n12           4         4    1      4  \n13           3         1    1      2  \n14           5         5    4      4  \n15           4         3    1      4  \n16           2         1    1      2  \n17           3         1    1      2  \n18           4         1    2      4  \n19           3         1    1      2  \n20           5         4    4      4  \n21           7        10    1      4  \n22           2         1    1      2  \n23           7         3    1      4  \n24           3         1    1      2  \n25           3         6    1      4  \n26           2         1    1      2  \n27           2         1    1      2  \n28           2         1    1      2  \n29           1         1    1      2  \n30           2         1    1      2  \n31           3         1    1      2  \n32           7         4    3      4  \n33           3         1    1      2  \n34           2         1    1      2  \n35           2         1    1      2  \n36           8         9    1      4  \n37           7         1    1      2  \n38           5         6    1      4  \n39           7         5    1      4  \n40           7         8    1      2  \n41           6         5    2      4  \n42           7         3    3      4  \n43           3         1    1      4  \n44           8        10    1      4  \n45           2         1    2      2  \n46           4         8    1      4  \n47           2         1    1      2  \n48           3         1    1      2  \n49           3         8    2      4  "
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "cell_df = pd.read_csv(\"cell_samples.csv\")\ncell_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using my_data as the Drug.csv data read by pandas, declare the following variables:\n\n    X as the Feature Matrix (data of my_data)\n    y as the response vector (target)\n\nRemove the column containing the ID.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]])"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize',\n       'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']].values\nX[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0    2\n1    2\n2    2\n3    2\n4    2\nName: Class, dtype: int64"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y = cell_df[\"Class\"]\ny[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Setting up the Decision Tree\nWe will be using train/test split on our decision tree. Let's import train_test_split from sklearn.cross_validation. "
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now train_test_split will return 4 different parameters. We will name them:\nX_trainset, X_testset, y_trainset, y_testset\n\nThe train_test_split will need the parameters:\nX, y, test_size=0.3, and random_state=3.\n\nThe X and y are the arrays required before the split, the test_size represents the ratio of the testing dataset, and the random_state ensures that we obtain the same splits."
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "2- Model"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will first create an instance of the DecisionTreeClassifier called cancerTree.\nInside of the classifier, specify criterion=\"entropy\" so we can see the information gain of each node. "
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "cancerTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\ncancerTree # it shows the default parameters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Next, we will fit the data with the training feature matrix X_trainset and training response vector y_trainset\n"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "cancerTree.fit(X_trainset,y_trainset)"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "predTree = cancerTree.predict(X_testset)"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[2 2 2 4 4]\n595    2\n348    4\n660    2\n210    4\n427    4\nName: Class, dtype: int64\n"
                }
            ],
            "source": "print (predTree [0:5])\nprint (y_testset [0:5])\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "3- Evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "DecisionTrees's Accuracy:  0.9463414634146341\n"
                }
            ],
            "source": "from sklearn import metrics\nimport matplotlib.pyplot as plt\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_testset, predTree))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using f1-score:"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.9461191953196476"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import f1_score\nf1_score(y_testset, predTree, average='weighted')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using Jaccard"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.9463414634146341"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_testset, predTree)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Visualisation"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline "
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "#!conda install -c conda-forge pydotplus -y"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "#!conda install -c conda-forge python-graphviz -y"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<matplotlib.image.AxesImage at 0x7f1f90498fd0>"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dot_data = StringIO()\nfilename = \"cancertree.png\"\nfeatureNames = cell_df.columns[0:9]\ntargetNames = cell_df[\"Class\"].unique().tolist()\nout=tree.export_graphviz(cancerTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset).astype(str), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "conda-env-python-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}